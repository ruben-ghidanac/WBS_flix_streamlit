# -*- coding: utf-8 -*-
"""RUBEN_the name of a movie, and a number (n).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oJwiEfNgZ0AWvjL9h-ihpUKr3Ja5kDAf

## Importing the libraries and read the data
"""

# Importing the libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Read the data

url_links = "https://drive.google.com/file/d/1lFay3ImDdtXWAsmOyOl0q4WQfoVZShQD/view?usp=share_link"
path_links = "https://drive.google.com/uc?export=download&id="+url_links.split("/")[-2]
links = pd.read_csv(path_links)

url_movies = "https://drive.google.com/file/d/1UXEccAh6JovPnLIG8VG5sm1nd7v8UNwW/view?usp=share_link"
path_movies = "https://drive.google.com/uc?export=download&id="+url_movies.split("/")[-2]
movies = pd.read_csv(path_movies)

url_ratings = "https://drive.google.com/file/d/12AYRrLehtsT8juNVtt_ytn6oR8OVnYS2/view?usp=share_link"
path_ratings = "https://drive.google.com/uc?export=download&id="+url_ratings.split("/")[-2]
ratings = pd.read_csv(path_ratings)

url_tags = "https://drive.google.com/file/d/1mV4n3WR4_J8NdAXGo1gI-I_ZcdWiZsTX/view?usp=share_link"
path_tags = "https://drive.google.com/uc?export=download&id="+url_tags.split("/")[-2]
tags = pd.read_csv(path_tags)

"""## Exploring the data"""

links.head(2)

movies.head(2)

ratings.head(2)

tags.head(2)

"""## Exercices from platform"""

# exercice from platform
import pandas as pd

A = [1, 1, 1, 2, 2]
movie_A = pd.Series(A, index = ["user_x", "user_y", "user_z", "user_i", "user_j"])

B = [3, 4, 5, 4, 5]
movie_B = pd.Series(B, index = ["user_x", "user_y", "user_z", "user_i", "user_j"])

movie_A.corr(movie_B)

# exercice from platform
from pandas import DataFrame
from sklearn.metrics.pairwise import cosine_similarity
  
df = DataFrame({
'user_x': [1, 3, 2, 4],
'user_y': [1, 4, 3, 4],
'user_z': [1, 5, 5, 1] 
},
index=['movie_A', 'movie_B', 'movie_C', 'movie_D'])

# exercice from platform
from sklearn.metrics.pairwise import cosine_similarity
cosine_similarity(df.T)

# exercice from platform
cosine_similarity(df)

"""## Movie Challenge 1:"""

movies_crosstab = pd.pivot_table(data=ratings, values='rating', index='userId', columns='movieId')

movies_crosstab.sample()

# I will change the approach, instead movies_id ...to be movies_name
def similar_movies(movies_id, n):
    
  movie_ratings = movies_crosstab[movies_id]
  movie_ratings = movie_ratings[movie_ratings>=0] # exclude NaNs

  similar_to_movie_id = movies_crosstab.corrwith(movies_crosstab[movies_id])
  similar_to_movie_id.dropna(inplace=True)
  similar_to_movie_id = pd.DataFrame(similar_to_movie_id, columns=['PearsonR'])
  similar_to_movie_id.dropna(inplace=True)
      
  rating_r = pd.DataFrame(ratings.groupby('movieId')['rating'].mean())
  rating_r['rating_count'] = ratings.groupby('movieId')['rating'].count()

  similar_to_movie_id = similar_to_movie_id.join(rating_r['rating_count'])
  similar_to_movie_id.drop(movies_id, inplace=True)
  top_n = similar_to_movie_id[similar_to_movie_id['rating_count']>=10].sort_values('PearsonR', ascending=False).head(n)
  return top_n

similar_movies(10,3)

"""## Movie Challenge 2:

Your task: create a function that takes the users userId, and a number (n) and outputs the n most recommended movies based on the cosine similarity of other users.
"""

users_items = pd.pivot_table(data=ratings, values='rating', index='movieId', columns='userId')

users_items.head()

# your code here



def recommendations_for_specific_user_id(user_id, top_n_movies):
  
  # replace NaNs with zeros, the cosine similarity can't be computed with NaN's
  users_items.fillna(0, inplace=True)

  # compute cosine similarities
  user_similarities = pd.DataFrame(cosine_similarity(users_items),
                                 columns=users_items.index, 
                                 index=users_items.index)
  
  # compute the weights for 'user_id'
  weights = (
      user_similarities.query("movieId!=@user_id")[user_id] / sum(user_similarities.query("movieId!=@user_id")[user_id]))
  users_items.loc[user_id,:]==0

  # select movies that the 'user_id' has not seen
  not_seen_movies = users_items.loc[users_items.index!=user_id, users_items.loc[user_id,:]==0]
  not_seen_movies.T

  # dot product between the not-visited-restaurants and the weights
  weighted_averages = pd.DataFrame(not_seen_movies.T.dot(weights), columns=["predicted_rating"])

  # find the top 'n' movies from the rating predictions
  recommendations = weighted_averages.merge(movies, left_index=True, right_on="movieId")
  top_n = recommendations.sort_values("predicted_rating", ascending=False).head(top_n_movies)
  
  return top_n

def show_seen_movies_for_specific_user_id(user_id):
  users_items_with_names = users_items.merge(movies, left_index=True, right_on="movieId")

  my_list = []

  for i in users_items_with_names.index:
    if users_items_with_names[user_id][i]>0:
      my_list.append(i)

  my_list = pd.DataFrame(my_list)
  my_list = my_list.merge(movies, left_index=True, right_on="movieId")
  my_list = my_list.drop(['movieId'], axis=1)
  my_list.rename(columns = {0:'movieId'}, inplace = True)
  
  return my_list

recommendations_for_specific_user_id(2, 5)

show_seen_movies_for_specific_user_id(2)
